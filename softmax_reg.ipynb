{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Softmax Reg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcaN85kTdI0t"
      },
      "source": [
        "## Pytorch로 Softmax Regression 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYqUiKpTdABq"
      },
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
        "y_train = torch.FloatTensor([[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0], [1,0,0], [1,0,0]])\n",
        "\n",
        "W = torch.zeros(4,3, requires_grad=True)\n",
        "b = torch.zeros(1,3, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([W,b], lr=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92voa6Gtdlax",
        "outputId": "86ba88f2-e421-419c-8de1-cf195a47a628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "for epoch in range(3001):\n",
        "    # hypothesis = torch.softmax(torch.mm(x_train, W)+b, dim=1)\n",
        "    # cost = -torch.mean(torch.sum(y_train * torch.log(hypothesis), dim=1))\n",
        "    \n",
        "    hypothesis = (torch.mm(x_train, W)+b).softmax(dim=1)\n",
        "    cost = -(y_train * torch.log(hypothesis)).sum(dim=1).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 300 == 0:\n",
        "        print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, cost: 1.098612\n",
            "epoch: 300, cost: 0.105263\n",
            "epoch: 600, cost: 0.042634\n",
            "epoch: 900, cost: 0.023111\n",
            "epoch: 1200, cost: 0.014479\n",
            "epoch: 1500, cost: 0.009879\n",
            "epoch: 1800, cost: 0.007124\n",
            "epoch: 2100, cost: 0.005338\n",
            "epoch: 2400, cost: 0.004113\n",
            "epoch: 2700, cost: 0.003236\n",
            "epoch: 3000, cost: 0.002588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0jhJnM1eIg3"
      },
      "source": [
        "x가 [1,11,10,9], [1,3,4,3], [1,1,0,1] 일 때, y값은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B51r6iC-d7Zo",
        "outputId": "adc3633d-e080-4b44-8c6a-7ec41294ee7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "W.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "\n",
        "x_test = torch.FloatTensor([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
        "test_all = torch.softmax(torch.mm(x_test, W)+b, dim=1)\n",
        "\n",
        "print(test_all)\n",
        "print(torch.argmax(test_all, dim=1))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000e+00, 5.5164e-19, 7.0150e-38],\n",
            "        [1.4800e-02, 7.4294e-01, 2.4226e-01],\n",
            "        [1.2256e-33, 9.0835e-12, 1.0000e+00]])\n",
            "tensor([0, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icAOn2XwfD-f"
      },
      "source": [
        "조금 더 깔끔하게 Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BboUJNxNfGm6",
        "outputId": "62ada6c3-9a9d-40f9-ab6b-a25c40c9c57f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.FloatTensor([[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7]])\n",
        "y_train = torch.LongTensor([2,2,2,1,1,1,0,0])\n",
        "\n",
        "model = nn.Linear(4,3)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    z = model(x_train)\n",
        "    cost = F.cross_entropy(z, y_train)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 300 == 0:\n",
        "        print(\"epoch: {}, cost: {:.6f}\".format(epoch, cost.item()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, cost: 4.774090\n",
            "epoch: 300, cost: 0.028424\n",
            "epoch: 600, cost: 0.011209\n",
            "epoch: 900, cost: 0.006053\n",
            "epoch: 1200, cost: 0.003798\n",
            "epoch: 1500, cost: 0.002597\n",
            "epoch: 1800, cost: 0.001877\n",
            "epoch: 2100, cost: 0.001409\n",
            "epoch: 2400, cost: 0.001088\n",
            "epoch: 2700, cost: 0.000857\n",
            "epoch: 3000, cost: 0.000686\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}